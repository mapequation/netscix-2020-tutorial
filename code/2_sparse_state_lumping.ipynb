{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sparse state networks \n",
    "Second-order dynamics on a physical network can be described by first-order dynamics on a second-order state network.\n",
    "\n",
    "We can represent this second-order network by it's _state transition matrix_ $P_{ij}$ with the probabilities for the random walker to transition from state node $i$ to state node $j$.\n",
    "\n",
    "In this view, we may note that some rows have similar probability distributions. We can measure how much information we lose when merging two state nodes with the [Jensen-Shannon Distance](https://en.wikipedia.org/wiki/Jensen%E2%80%93Shannon_divergence).\n",
    "\n",
    "The idea behind sparse state networks is that we can lump state nodes (within each physical node) that constrain the network flow in a similar way without losing (much) information."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transform to a general machine learning problem\n",
    "We will here solve the problem using a divisive clustering algorithm in [clustering_algorithm.py](./clustering_algorithm.py).\n",
    "\n",
    "In order to do that, we have to transform the state network into features usable for machine learning. We can do this with the help of the code in [state_network.py](./state_network.py).\n",
    "\n",
    "**TODO**\n",
    "- Import StateNetwork from state_network\n",
    "- Create a new StateNetwork using the `.from_paths(filename)` method to read in `../data/toy_paths.net`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read path data from file '../data/toy_paths.net'...\n",
      "Done, parsed 32/32 paths\n",
      " -> 12 return paths\n",
      " -> 12 states in training network\n",
      "Writing state network to file '../output/toy_states.net'...\n",
      "<StateNetwork phys_nodes=[\n",
      "\t<PhysNode id=5 containers=<Cluster id=0 state_ids=[1,9]>>\n",
      "\t<PhysNode id=4 containers=<Cluster id=1 state_ids=[2,11]>>\n",
      "\t<PhysNode id=1 containers=<Cluster id=2 state_ids=[3,7,10,12]>>\n",
      "\t<PhysNode id=2 containers=<Cluster id=3 state_ids=[4,8]>>\n",
      "\t<PhysNode id=3 containers=<Cluster id=4 state_ids=[5,6]>>\n",
      "/>\n"
     ]
    }
   ],
   "source": [
    "from state_network import StateNetwork\n",
    "\n",
    "order = 2\n",
    "net, _ = StateNetwork.from_paths(\"../data/toy_paths.net\", output_filename=\"../output/toy_states.net\", markov_order=order)\n",
    "net.aggregate(order)\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../figures/toy_states.png\" width=\"450\">\n",
    "\n",
    "Figure 1: Second-order state network in `output/toy_states.net`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature matrix\n",
    "\n",
    "The feature matrix for a physical node is simply the rows of the state transition matrix for the state nodes belonging to that physical node.\n",
    "\n",
    "To simplify, there is a `get_feature_matrix` method that removes all all-zero rows and columns in the feature matrix and provides a mapping back to the original state network. It returns a tuple `(X, T)`, where `X` is the feature matrix (np.array) of size (numNonDanglingStateNodes, numLinkedNodes) and `T` is a dictionary transforming row index in the feature matrix to state node id.\n",
    "\n",
    "**TODO**\n",
    "- Use the method above and get the feature matrix and rowToStateId map\n",
    "- Print the two items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature matrix for the central physical node:\n",
      "[[0.39690536 0.39174763 0.10663308 0.10471393]\n",
      " [0.10174558 0.10150646 0.40124342 0.39550454]\n",
      " [0.39658623 0.39976457 0.09535021 0.108299  ]\n",
      " [0.10601476 0.09681714 0.3971923  0.3999758 ]]\n",
      "row_index_to_state_ids:\n",
      "{0: [3], 1: [7], 2: [10], 3: [12]}\n"
     ]
    }
   ],
   "source": [
    "central_node = net.phys_nodes[1]\n",
    "X, row_index_to_state_ids = net.get_feature_matrix(central_node, order)\n",
    "\n",
    "print(f\"Feature matrix for the central physical node:\\n{X}\")\n",
    "print(f\"row_index_to_state_ids:\\n{row_index_to_state_ids}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Measure pairwise similarity\n",
    "Now we can compare rows pairwise and cluster the most similar rows together. The Jensen-Shannon distance is unfortunately not implemented in scikit-learn (though it exist in a [pull request](https://github.com/scikit-learn/scikit-learn/pull/4191)), so let's create it.\n",
    "\n",
    "**TODO**\n",
    "- Write a function that takes two equally sized arrays of probabilities as input and returns the Jensen-Shannon distance between them\n",
    "- Compute the Jensen-Shannon distance between the two different rows of the feature matrix, and check that at gives zero for same input\n",
    "\n",
    "Tips, using numpy:\n",
    "- Work with `np.asarray(x)` in the function to allow for both a numpy array and an ordinary python list as input\n",
    "- `np.log2(x)` can be modified to `np.log2(x, where = x>0)` to handle zeros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "0.5135537698931543\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def plogp(x):\n",
    "    x = np.asarray(x)\n",
    "    return x * np.log2(x, where = x>0)\n",
    "\n",
    "def entropy(x):\n",
    "    return -np.sum(plogp(x))\n",
    "\n",
    "def jensen_shannon_distance(x1, x2):\n",
    "    x1 = np.asarray(x1)\n",
    "    x2 = np.asarray(x2)\n",
    "    mix = (x1 + x2) / 2\n",
    "    return np.sqrt(entropy(mix) - (entropy(x1) + entropy(x2)) / 2)\n",
    "\n",
    "print(jensen_shannon_distance(X[0], X[0]))\n",
    "print(jensen_shannon_distance(X[0], X[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cluster with divisive clustering algorithm\n",
    "\n",
    "Now we can use the divisive clustering algorithm that uses the pairwise distance function as a metric. It can take as input the number of clusters you want. For the example feature matrix, it's two.\n",
    "\n",
    "**TODO**\n",
    "- Create a JSdivisiveClustering model and find two clusters based on the Jensen-Shannon distance\n",
    "- Use the row-to-stateId map to check which state nodes are clustered together (the left ones are state node 7 and 12, the right ones are state node 3 and 10)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: [3, 10], 1: [7, 12]}\n"
     ]
    }
   ],
   "source": [
    "from clustering_algorithm import JSdivisiveClustering\n",
    "\n",
    "labels = JSdivisiveClustering(X, net.tot_weight).divide_labels(n_clusters=2)\n",
    "\n",
    "label_to_state_ids = {label: [] for label in labels}\n",
    "\n",
    "for row_index, label in enumerate(labels):\n",
    "    label_to_state_ids[label].extend(row_index_to_state_ids[row_index])\n",
    "\n",
    "print(label_to_state_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lump whole network\n",
    "Now we are ready to run this on the whole network. For convenience, `StateNetwork` provides a method `cluster_state_nodes` that takes an argument `js_div_threshold`. This will divide clusters as long as the information gain is greater than the threshold.\n",
    "\n",
    "**TODO**\n",
    "- Cluster the whole state network using the method above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<StateNetwork phys_nodes=[\n",
      "\t<PhysNode id=5 containers=<Cluster id=5 state_ids=[1,9]>>\n",
      "\t<PhysNode id=4 containers=<Cluster id=6 state_ids=[2,11]>>\n",
      "\t<PhysNode id=1 containers=<Cluster id=7 state_ids=[3,10]><Cluster id=8 state_ids=[7,12]>>\n",
      "\t<PhysNode id=2 containers=<Cluster id=9 state_ids=[4,8]>>\n",
      "\t<PhysNode id=3 containers=<Cluster id=10 state_ids=[5,6]>>\n",
      "/>\n"
     ]
    }
   ],
   "source": [
    "net.cluster_state_nodes(order, js_div_threshold=1e-5)\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../figures/toy_states_lumped.png\" width=\"450\">\n",
    "\n",
    "Figure 2: Sparse state network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Did we lose any information?\n",
    "The state network has two properties `entropy_rate` and `lumped_entropy_rate` to calculate the average number of bits required to encode the random walk on each physical node.\n",
    "\n",
    "**TODO**\n",
    "- Run the methods above and check that the entropy rates stayed the same"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entropy rate before: 1.244833806460494\n",
      "Entropy rate after:  1.2449413025980005\n"
     ]
    }
   ],
   "source": [
    "print(f\"Entropy rate before: {net.entropy_rate}\")\n",
    "print(f\"Entropy rate after:  {net.lumped_entropy_rate}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing clustered state network to file '../output/toy_states_lumped.net'...\n",
      "# physical nodes: 5\n",
      "# clustered state nodes: 6\n",
      "*Vertices\n",
      "1 \"i\"\n",
      "2 \"j\"\n",
      "3 \"k\"\n",
      "4 \"l\"\n",
      "5 \"m\"\n",
      "*States\n",
      "#state_id physical_id \n",
      "5 5\n",
      "6 4\n",
      "7 1\n",
      "8 1\n",
      "9 2\n",
      "10 3\n",
      "*Links\n",
      "#source_id target_id weight\n",
      "5 6 8374\n",
      "5 7 8269\n",
      "6 5 8415\n",
      "6 7 8293\n",
      "7 6 6678\n",
      "7 5 6662\n",
      "7 10 1699\n",
      "7 9 1793\n",
      "8 10 6638\n",
      "8 9 6613\n",
      "8 6 1727\n",
      "8 5 1649\n",
      "9 10 8443\n",
      "9 8 8167\n",
      "10 8 8357\n",
      "10 9 8223\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "net.write_clustered_network(\"../output/toy_states_lumped.net\")\n",
    "print(Path('../output/toy_states_lumped.net').read_text())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now we have generated the sparse network (with lossless compression)\n",
    "<img src=\"../figures/toy_states.png\" width=\"450\">\n",
    "<img src=\"../figures/toy_states_lumped.png\" width=\"450\">\n",
    "\n",
    "Figure 3: The original second-order network and the sparse network formed by lumping similar state nodes within each physical node."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
